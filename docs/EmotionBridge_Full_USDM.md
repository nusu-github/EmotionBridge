# EmotionBridge 全体要求仕様書（USDM形式）

> **プロジェクト**: EmotionBridge — テキスト感情→既存キャラクターTTS韻律パラメータ自動変換  
> **対象範囲**: 全フェーズ（Phase 0〜4）  
> **作成日**: 2026-02-17  
> **ステータス**: v1.0 新設計準拠（SERベース設計全面廃止後）  
> **ID体系**: `EB-[カテゴリ記号][連番]-[下位要求番号]-[仕様連番3桁]`  
> **関連文書**: EB3-USDM（Phase 3詳細要求仕様書）、EB-P0-BD-001（Phase 0基本設計書）

---

## 1. システム全体要求

### 要求ID: EB-S01（プロジェクトゴール）

| 項目 | 内容 |
|------|------|
| **要求** | テキストを入力として受け取り、テキストに含まれる感情を自動分析し、VOICEVOX等の既存キャラクター音声合成エンジンの韻律パラメータに変換し、感情表現付き音声を生成する |
| **理由** | 既存キャラクターTTS（VOICEVOX、CeVIO等）はデフォルトではニュートラルな韻律で発話するため、感情表現が乏しい。特定キャラクターの声で感情表現を実現するにはパラメータ制御方式が唯一の現実解であり、その自動化が未解決課題であるため |
| **説明** | E2Eモデル（GPT-4o、Moshi等）をVoiceとして使用することは本プロジェクトの目的に合致しない。EmotionBridgeの本質は「既存キャラクター音声合成の韻律を自動調整する」ことにある。主要ターゲット: ずんだもん、副ターゲット: 四国めたん |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-S01-001 | \<入力\> | 日本語テキスト（SNS投稿程度の長さ〜数文程度）を入力とする | |
| EB-S01-002 | \<出力\> | VOICEVOX互換の制御パラメータ（5D韻律パラメータ＋スタイルID）および生成音声を出力する | |
| EB-S01-003 | \<感情カテゴリ\> | 対応する感情は6カテゴリ: anger, disgust, fear, happy, sad, surprise とする | 旧設計の8D Plutchik（joy, sadness, anticipation, surprise, anger, fear, disgust, trust）から、JVNV対応の6カテゴリに変更 |
| EB-S01-004 | \<韻律制御パラメータ\> | 5D制御パラメータ: pitch\_shift（F0平均高低）、pitch\_range（F0変動幅）、speed（発話速度）、energy（音響エネルギー）、pause\_weight（休止長）。各パラメータは[-1.0, +1.0]の範囲 | |
| EB-S01-005 | \<パイプライン構成\> | テキスト → Phase 0感情分類 → パラメータ生成器 → スタイル選択 → VOICEVOX音声合成 → 音声出力 の順で処理する | |

### 要求ID: EB-S02（設計原則）

| 項目 | 内容 |
|------|------|
| **要求** | 正解信号に物理量ベースの韻律特徴量を使用し、間接的推定を排除した設計とする |
| **理由** | 旧設計（v0.1–v0.3）ではSER（emotion2vec+）をweak teacherとして使用し、テキスト感情分析→SER→triplet loss→パラメータ回帰の多段ノイズ連鎖が発生していた。各段階の不確実性が掛け算で累積し、最終出力の信頼度が構造的に担保できなかったため |
| **説明** | 新設計ではJVNV感情音声コーパスの韻律特徴量（eGeMAPS 88D物理量）を正解信号とし、SERの代わりにJVNV実測韻律、感情埋め込み空間の代わりにeGeMAPS物理量空間を使用する。これにより中間層が4段→2段に削減される |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-S02-001 | \<正解信号\> | JVNV感情音声コーパス（1,615件、6感情、人間認識率94%、CC BY-SA 4.0）から抽出したeGeMAPS韻律特徴量を正解信号とする | emotion2vec+スコア（旧設計）は使用しない |
| EB-S02-002 | \<比較空間\> | openSMILE eGeMAPSv02（88D）の物理量空間で韻律比較を行う | 感情埋め込み空間（旧設計、ブラックボックス）は使用しない |
| EB-S02-003 | \<ドメインギャップ対応\> | JVNV（人間音声）とVOICEVOX（合成音声）のドメインギャップは話者/スタイル内z-score正規化で吸収する | V-03で正規化後overlap ratio 0.72を確認済み |

---

## 2. Phase 0: テキスト感情分類器

### 要求ID: EB-P0-01（テキスト感情分類）

| 項目 | 内容 |
|------|------|
| **要求** | 入力テキストの感情を分析し、6感情カテゴリの確率分布を出力する分類器を訓練する |
| **理由** | 推論パイプラインの入口として、テキストから感情情報を抽出する必要がある。旧設計（8D Plutchik回帰、trust相関0.36でNo-Go）から6感情カテゴリ分類に切り替え、JVNV感情ラベルと直接対応させるため |
| **説明** | Phase 0は他コンポーネント（TTS・SER）への依存がなく、単独で訓練・評価が完結する。旧Phase 0の基本設計書（EB-P0-BD-001）から再設計 |

#### 下位要求: EB-P0-01-01（学習データ構築）

| 項目 | 内容 |
|------|------|
| **要求** | WRIMEコーパスから6感情カテゴリの学習データを構築する |
| **理由** | WRIMEは日本語テキスト感情コーパスとして最大規模（43,200件）であり、Plutchik 8感情の強度ラベルが付与されているため、6感情への変換が可能 |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P0-01-01-001 | \<データソース\> | WRIME Ver1（43,200件、Hugging Face shunk031/wrime経由で取得）を使用する | |
| EB-P0-01-01-002 | \<ラベル種別\> | 客観ラベルの平均値（avg\_readers）を使用する。書き手の主観ラベルは使用しない | EmotionBridgeは「読み手が感じる感情」を音声に乗せる設計 |
| EB-P0-01-01-003 | \<感情マッピング\> | joy→happy, sadness→sad, anger→anger, fear→fear, disgust→disgust, surprise→surprise の直接対応で変換する。anticipation, trustは除外する | JVNVに対応する感情カテゴリが存在しないため |
| EB-P0-01-01-004 | \<フィルタリング\> | 8感情すべての客観強度が1以下のサンプルを除外する（感情が弱すぎるサンプルの学習ノイズ排除） | 全体の30–50%が除外される可能性あり。除外数を記録し極端な場合は閾値調整 |
| EB-P0-01-01-005 | \<ラベル変換\> | WRIMEの連続強度値（0–3）から6クラス分類ラベルへの変換方式を定義する | 決定: argmax方式を本採用。soft labelは補助比較実験として評価 |
| EB-P0-01-01-006 | \<データ分割\> | フィルタリング後のデータに対してstratified split（train 80% / val 10% / test 10%）を適用する。stratification keyは最大強度感情のargmax | |

#### 下位要求: EB-P0-01-02（分類モデル）

| 項目 | 内容 |
|------|------|
| **要求** | BERTベースの6クラス感情分類モデルを設計・訓練する |
| **理由** | 日本語テキストからの感情分類にはBERTの文脈理解能力が有効であり、旧Phase 0でも使用実績がある |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P0-01-02-001 | \<ベースモデル\> | tohoku-nlp/bert-base-japanese-whole-word-masking を使用する | 旧Phase 0と同一。約110Mパラメータ |
| EB-P0-01-02-002 | \<出力層\> | 6クラス分類ヘッド（Softmax）を追加し、各感情の確率分布を出力する | 旧設計のSigmoid 8D回帰から変更 |
| EB-P0-01-02-003 | \<トークナイゼーション\> | 最大シーケンス長128トークン。\[UNK\]トークンの出現率が5%を超える場合はテキスト前処理（絵文字除去、顔文字正規化、URL除去等）を追加する | |
| EB-P0-01-02-004 | \<訓練\> | AdamWオプティマイザ、BERT学習率2e-5、分類ヘッド学習率1e-3、weight decay 0.01、linear warmup（全ステップの10%）+ linear decay、バッチサイズ32、最大10エポック、early stopping patience 3エポック | |
| EB-P0-01-02-005 | \<再現性\> | random\_seed=42を全乱数生成器に固定、cudnn.deterministic=True、全ハイパーパラメータをYAMLに記録 | |

#### 下位要求: EB-P0-01-03（推論インターフェース）

| 項目 | 内容 |
|------|------|
| **要求** | 訓練済みモデルをラップしたEmotionEncoderクラスを提供し、テキストから6D感情確率ベクトルを返す推論APIとする |
| **理由** | Phase 3のパラメータ生成器への入力として、統一的なインターフェースが必要 |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P0-01-03-001 | \<メソッド\> | encode(text: str) → np.ndarray\[6\]（単一テキスト）、encode\_batch(texts: List\[str\]) → np.ndarray\[N, 6\]（バッチ処理）を提供する | 旧設計の8Dから6Dに変更 |
| EB-P0-01-03-002 | \<出力仕様\> | 出力はnumpy.ndarray型の6次元ベクトル。各次元は\[0, 1\]の範囲のfloat値。次元順序は\[anger, disgust, fear, happy, sad, surprise\]で固定 | |
| EB-P0-01-03-003 | \<デバイス\> | GPU（CUDA）上でのバッチ処理に対応する。CPUフォールバックも可能とする | Phase 1のデータ生成で大量テキストを処理するため |

#### 下位要求: EB-P0-01-04（評価・Go/No-Go）

| 項目 | 内容 |
|------|------|
| **要求** | test setで分類精度を評価し、Phase 3移行の可否を判定する |
| **理由** | Phase 0の出力品質がパイプライン全体の上限となるため、最低品質条件を設けて品質を担保する |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P0-01-04-001 | \<評価指標\> | 6感情分類の精度（accuracy）、感情別F1スコア、マクロF1を算出する | 旧設計のMSE/Pearson rは回帰用指標。分類タスクに合わせて変更 |
| EB-P0-01-04-002 | \<Go/No-Go\> | マクロF1 ≥ 0.40、かつanger/happy/sadの個別F1 ≥ 0.50 を最低条件とする | 確定済み（分類タスク用閾値） |
| EB-P0-01-04-003 | \<不達成時対策\> | (1)エラー分析による原因特定、(2)データ拡張、(3)ベースモデル変更（DeBERTa-v2-japanese等）、(4)基準の見直し の優先順位で対策する | |

---

## 3. Phase 1: VOICEVOXグリッドサーチ音声生成

### 要求ID: EB-P1-01（グリッドサーチ音声生成）

| 項目 | 内容 |
|------|------|
| **要求** | VOICEVOXの5D制御パラメータの組み合わせを網羅的に探索し、各パラメータ設定で音声を生成し、韻律応答空間を構築する |
| **理由** | 「この制御パラメータを設定するとどのような韻律の音声が生成されるか」を物理的に計測し、感情プロファイルとのマッチングの基盤データとするため |
| **説明** | Phase 1完了時点で25,416件のグリッドサーチ音声が生成済み |

#### 下位要求: EB-P1-01-01（パラメータグリッド設計）

| 項目 | 内容 |
|------|------|
| **要求** | 5D制御パラメータの値域をグリッド状に分割し、全組み合わせを定義する |
| **理由** | パラメータ空間を均一にカバーすることで、マッチング時に特定領域にバイアスがかからないようにするため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P1-01-01-001 | \<パラメータ範囲\> | 5Dパラメータ（pitch\_shift, pitch\_range, speed, energy, pause\_weight）のそれぞれを[-1.0, +1.0]の範囲で探索する | |
| EB-P1-01-01-002 | \<グリッド密度\> | 各軸の刻み幅を定義し、全組み合わせの音声を生成する。生成件数は約200テキスト × パラメータ組み合わせ = 25,416件 | |
| EB-P1-01-01-003 | \<テキスト\> | 感情表現を含む約200件の日本語テキストを入力として使用する | テキスト多様性の制約あり（EB-S-制約04参照） |

#### 下位要求: EB-P1-01-02（音声生成）

| 項目 | 内容 |
|------|------|
| **要求** | VOICEVOXエンジンを使用し、各パラメータ組み合わせで音声を生成・保存する |
| **理由** | 韻律特徴量抽出の入力データとなる音声ファイルを物理的に生成する必要がある |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P1-01-02-001 | \<対象キャラクタ\> | ずんだもん（主要ターゲット: style\_id 3, 1, 7, 5, 22, 38, 75, 76）、四国めたん（副ターゲット: style\_id 2, 0, 6, 4, 36, 37）のスタイルごとに生成する | |
| EB-P1-01-02-002 | \<VOICEVOXエンジン\> | VOICEVOXエンジンをローカルで起動し、REST APIを介して音声合成を実行する | |
| EB-P1-01-02-003 | \<メタデータ\> | 各音声ファイルに紐付くメタデータ（テキスト、5Dパラメータ値、style\_id、キャラクタ名）をCSVまたはJSON形式で記録する | |

---

## 4. Phase 2: 検証実験

### 要求ID: EB-P2-01（設計仮説の検証）

| 項目 | 内容 |
|------|------|
| **要求** | 新設計（v1.0）の3つの前提仮説を実験的に検証し、Phase 3着手の可否をGo/No-Go判定する |
| **理由** | 新設計の成立条件である「JVNV韻律空間上で感情が分離するか」「VOICEVOXのパラメータが韻律空間で系統的に応答するか」「ドメインギャップを正規化で吸収できるか」を実装前に確認し、Phase 3の手戻りリスクを排除するため |

#### 下位要求: EB-P2-01-01（V-01: JVNV感情分離性検証）

| 項目 | 内容 |
|------|------|
| **要求** | JVNV感情音声の韻律特徴量空間上で、感情カテゴリ間の分離性を定量評価する |
| **理由** | JVNVの韻律特徴量が感情情報を保持していなければ、これを正解信号として使用する新設計の前提が崩壊するため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P2-01-01-001 | \<全体分離度\> | 88D eGeMAPS空間でのsilhouetteスコアを算出する | 結果: 0.009。6感情クラスタとしては不成立 |
| EB-P2-01-01-002 | \<ペアワイズ分離度\> | 全15ペア（6C2）のsilhouetteスコアをTier1（11D）サブセットで算出する | 結果: anger–sad 0.284（最大）、fear–surprise 0.026（最小） |
| EB-P2-01-01-003 | \<Arousal/Valence回帰\> | 韻律特徴量からArousal（R² ≥ 0.30）、Valence（R² ≥ 0.15）を回帰予測できるか検証する | 結果: Arousal R² 0.345（達成）、Valence R² 0.193（達成） |
| EB-P2-01-01-004 | \<Go/No-Go基準\> | Conditional Go: 6感情離散クラスタリング不成立だが韻律空間に感情情報が存在し、anger/happy/sadが明確に分離可能であること | 判定結果: Conditional Go |

#### 下位要求: EB-P2-01-02（V-02: VOICEVOX韻律応答性検証）

| 項目 | 内容 |
|------|------|
| **要求** | VOICEVOXの5D制御パラメータが韻律特徴空間上で系統的な変動を生じさせることを確認する |
| **理由** | 制御パラメータが韻律空間上で意味のある変動を起こさなければ、パラメータ調整による感情表現が不可能であるため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P2-01-02-001 | \<応答性指標\> | 各制御軸と韻律特徴量間の偏相関を算出し、主要な応答特徴を特定する | |
| EB-P2-01-02-002 | \<Go/No-Go基準\> | 全5軸について、少なくとも1つの韻律特徴量と偏相関 ≥ 0.4 の関係が確認できること | 判定結果: Go。pitch\_shift 0.982, pitch\_range 0.615, speed 0.775, energy 0.778, pause\_weight 0.413 |

#### 下位要求: EB-P2-01-03（V-03: ドメインギャップ・感情マッチング検証）

| 項目 | 内容 |
|------|------|
| **要求** | JVNV（人間音声）とVOICEVOX（合成音声）のドメインギャップを正規化で吸収できることを確認し、感情マッチングが文献整合的なパラメータパターンを返すことを検証する |
| **理由** | ドメインギャップが大きすぎると韻律距離による比較が無意味になり、マッチング結果が信頼できなくなるため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P2-01-03-001 | \<ギャップ指標\> | Wasserstein距離、MMD、overlap ratioで正規化前後のドメインギャップを定量化する | 結果: 正規化後 Wasserstein 0.15、MMD 0.005、overlap 0.72 |
| EB-P2-01-03-002 | \<マッチング検証\> | 感情ごとの推奨パラメータパターンが感情韻律研究の文献知見と整合することを確認する | 結果: anger→energy最大・pitch\_range最大、happy→pitch\_shift最大・speed正、sad→energy最小 等、文献整合的 |
| EB-P2-01-03-003 | \<聴取確認\> | 推奨パラメータで生成した音声をデフォルトと比較聴取し、感情方向への変化を確認する | 結果:「ニュートラルよりは確実にマシ。劇的ではないが5D制御の範囲内で妥当」 |
| EB-P2-01-03-004 | \<Go/No-Go基準\> | overlap ratio ≥ 0.60 かつ 感情マッチング結果が文献知見と矛盾しないこと | 判定結果: Go |

---

## 5. Phase 3: 韻律マッチング・パラメータ生成・統合

### 要求ID: EB-P3-01（Phase 3全体）

| 項目 | 内容 |
|------|------|
| **要求** | JVNV韻律プロファイルとVOICEVOX韻律応答空間を構築し、テキスト感情からVOICEVOXパラメータを自動生成するパラメータ生成器を訓練し、スタイル選択を統合し、エンドツーエンドの推論パイプラインを完成させる |
| **理由** | Phase 0–2で確立した基盤（感情分類器、グリッドサーチ音声、検証済み設計仮説）を統合し、EmotionBridgeの中核機能を実現するため |
| **説明** | Phase 3の詳細要求仕様はEB3-USDM（Phase 3詳細要求仕様書）に記載。ここでは全体要求レベルでの参照に留める |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P3-01-001 | \<サブフェーズ構成\> | Phase 3a（基盤構築）→ Phase 3b（パラメータ生成器）→ Phase 3c（スタイル統合）→ Phase 3d（主観評価・最終調整）の順に実施する | |
| EB-P3-01-002 | \<Phase 3a\> | Phase 0再学習（6クラス分類）、JVNV韻律プロファイル構築、VOICEVOX韻律特徴量抽出・正規化、スタイル別プロファイル構築、感情-スタイルマッピング（ルールベース）を実施する | 詳細: EB3-A01, EB3-B01, EB3-C01, EB3-E01-01 |
| EB-P3-01-003 | \<Phase 3b\> | 韻律距離ベースの教師データ構築、パラメータ生成器の訓練、ラウンドトリップ評価、ハイパーパラメータ調整を実施する | 詳細: EB3-D01, EB3-B01-02, EB3-G01-01 |
| EB-P3-01-004 | \<Phase 3c\> | 5Dパラメータ＋スタイル選択の統合推論、スタイル混合の実験（任意）、定量評価を実施する | 詳細: EB3-E01-02, EB3-F01 |
| EB-P3-01-005 | \<Phase 3d\> | パイロット聴取評価（5–10名）、評価結果に基づく調整、ドキュメント整備・コード公開準備を実施する | 詳細: EB3-G01-02, EB3-H01, EB3-N02 |

### 要求ID: EB-P3-02（評価基準）

| 項目 | 内容 |
|------|------|
| **要求** | Phase 3の成果を定量・主観の両面で評価し、システムの有効性を判定する |
| **理由** | 韻律マッチングの物理的妥当性と人間が知覚する感情表現の自然さは別の観点であり、両方を満たさないとシステムとして有効とは判断できないため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P3-02-001 | \<定量目標1\> | ラウンドトリップ韻律距離の必達目標はV-03基準（mean 3.84）比+10%以内、ストレッチ目標は3.84未満 | |
| EB-P3-02-002 | \<定量目標2\> | 感情分類一致率: anger/happy/sadで60%以上 | |
| EB-P3-02-003 | \<定量目標3\> | パラメータ予測MAE: 各軸0.2以内 | |
| EB-P3-02-004 | \<主観評価\> | A/Bテスト、5段階MOS、感情識別テストの3手法で実施。パイロット（5–10名）を先行 | |

---

## 6. Phase 4: 拡張（将来）

### 要求ID: EB-P4-01（他TTSキャリブレーション）

| 項目 | 内容 |
|------|------|
| **要求** | VOICEVOX以外のTTSエンジン（CeVIO, Style-Bert-VITS2等）に対してEmotionBridgeのパラメータ生成を適用可能にする |
| **理由** | EmotionBridgeの汎用性を高め、ユーザーの選択肢を広げるため |
| **説明** | 各TTSエンジンの制御パラメータ体系が異なるため、エンジンごとのグリッドサーチ＋キャリブレーションが必要。Phase 4で設計 |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P4-01-001 | \<対象\> | CeVIO AI、Style-Bert-VITS2を第一候補とする | 暫定（T.B.D）: Phase 3完了後に対象TTSを確定 |
| EB-P4-01-002 | \<方式\> | Phase 1と同様のグリッドサーチ＋eGeMAPS抽出＋正規化＋マッチングのパイプラインを各TTSエンジンに適用する | |

### 要求ID: EB-P4-02（モーラレベル韻律制御）

| 項目 | 内容 |
|------|------|
| **要求** | 文レベルの5Dパラメータ制御に加え、モーラ（音節）レベルでの韻律制御（vowel\_length, consonant\_length）を導入する |
| **理由** | 文レベルの韻律制御では表現できない細かな感情ニュアンス（語末の伸ばし、言い淀み等）をモーラレベルで実現し、感情表現の品質を向上させるため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P4-02-001 | \<制御対象\> | VOICEVOXのモーラレベルパラメータ（vowel\_length, consonant\_length）を制御対象とする | 認定仕様（要求にて特定済み） |

### 要求ID: EB-P4-03（感情強度の連続制御）

| 項目 | 内容 |
|------|------|
| **要求** | 感情カテゴリの離散的な選択に加え、感情の強度（弱い怒り〜強い怒り等）を連続的に制御可能にする |
| **理由** | 同じ感情カテゴリでもテキストによって感情の強さが異なるため、強度に応じたパラメータのスケーリングが表現の自然さに寄与する |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P4-03-001 | \<方式\> | Phase 0の分類確率値を強度の代理指標として使用し、推奨パラメータに強度係数を乗じてスケーリングする方式を第一候補とする | 暫定（T.B.D）: Phase 4設計時に方式を確定 |

### 要求ID: EB-P4-04（E2Eモデル音声による教師データ補完）

| 項目 | 内容 |
|------|------|
| **要求** | E2E音声合成モデル（GPT-4o等）が生成する感情音声の韻律特徴量をJVNV教師データの補完に使用する可能性を検討する |
| **理由** | JVNVは1,615件（4話者）と限定的であり、教師データの多様性を増やすことで感情プロファイルの頑健性が向上する可能性があるため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-P4-04-001 | \<前提\> | E2Eモデルの音声をVoiceとして使用するのではなく、教師データ補完のための韻律参照元としてのみ使用する | EmotionBridgeの目的（既存キャラクターTTSの韻律調整）とは明確に区別 |

---

## 7. 横断要求: 配布・ライセンス・再現性

### 要求ID: EB-X01（配布方針）

| 項目 | 内容 |
|------|------|
| **要求** | コードと設計文書を公開し、データ・モデル重み・中間成果物は非公開とし、利用者が自らデータを準備して初めてパイプラインを動かせる構造にする |
| **理由** | 音声合成の自動化を安易に悪用する用途（無断での大量コンテンツ生成等）への技術的フィルターとして機能させ、手順を理解し実行できる開発者のみが利用可能とするため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-X01-001 | \<公開物\> | 実験コード（全フェーズの全スクリプト）、設計文書・調査報告書、手順書（環境構築、データ準備、実行手順）を公開する | |
| EB-X01-002 | \<非公開物\> | JVNVから抽出した韻律特徴量データ、Phase 1グリッドサーチ音声、学習済みモデルの重み、正規化パラメータ・スコアテーブル等の中間成果物は公開しない | |
| EB-X01-003 | \<利用者準備\> | 利用者は以下を自ら準備する: (1) JVNVコーパスのダウンロード、(2) VOICEVOXエンジンのローカル起動、(3) グリッドサーチ音声の自己生成、(4) 韻律特徴量の自己抽出 | |

### 要求ID: EB-X02（ライセンス適合性）

| 項目 | 内容 |
|------|------|
| **要求** | 使用するすべての外部リソースのライセンス条件を遵守し、ライセンス上のリスクを明示的に管理する |
| **理由** | ライセンス違反はプロジェクトの配布・商用化を阻害し、法的リスクを生じるため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-X02-001 | \<JVNV\> | CC BY-SA 4.0に準拠。派生物もCC BY-SA。韻律特徴量データ自体は再配布しない | |
| EB-X02-002 | \<WRIME\> | 研究用途のみのライセンスに準拠。商用利用時は権利者に確認する | 暫定（T.B.D）: 商用化検討時に確認 |
| EB-X02-003 | \<openSMILE\> | 研究フェーズでは無償利用。商用化時はlibrosa+pyworld代替実装またはopenSMILE商用ライセンス取得 | |
| EB-X02-004 | \<VOICEVOX\> | キャラクターごとの利用規約に準拠。商用利用条件はキャラクターごとに個別確認 | |
| EB-X02-005 | \<BERTモデル\> | tohoku-nlp/bert-base-japanese-whole-word-masking のライセンスに準拠 | |

### 要求ID: EB-X03（再現性）

| 項目 | 内容 |
|------|------|
| **要求** | 第三者が手順書に従ってパイプライン全体を再現可能であること |
| **理由** | 研究としての信頼性と、配布方針（「コードは動作するが、データは自分で作る」）の実現に不可欠 |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB-X03-001 | \<環境構築\> | 必要なライブラリ・ツールのバージョンを固定し、環境構築手順を文書化する | |
| EB-X03-002 | \<乱数シード\> | 全フェーズでrandom\_seed=42を統一し、再現性を確保する | |
| EB-X03-003 | \<設定管理\> | 全フェーズのハイパーパラメータをYAMLファイルに記録し、チェックポイントとともに保存する | |

---

## 暫定事項（T.B.D）一覧（全体）

| 仕様ID | 内容 | 決定期限 | 決定者 |
|--------|------|----------|--------|
| EB-P4-01-001 | Phase 4対象TTSエンジンの確定 | Phase 3完了後 | プロジェクト実装者 |
| EB-P4-03-001 | 感情強度連続制御の方式確定 | Phase 4設計時 | プロジェクト実装者 |
| EB-X02-002 | WRIME商用利用可否の確認 | 商用化判断時 | プロジェクト実装者 |

解消済み:
- EB-P0-01-01-005（WRIME連続強度→6クラスラベル変換）はargmax本採用で確定済み
- EB-P0-01-04-002（分類タスク用Go/No-Go閾値）は確定済み

※ Phase 3内部のT.B.DはEB3-USDM（Phase 3詳細要求仕様書）に記載

---

## 既知の制約（全体）

| ID | 制約 | 影響 | 対応方針 |
|----|------|------|----------|
| 制約01 | VOICEVOXの5D制御パラメータの範囲・粒度に依存 | 感情表現は「ニュートラルより確実にマシ」が現実的目標水準 | スタイル選択との組み合わせ、Phase 4でモーラレベル制御を追加 |
| 制約02 | anger/happy/sadは韻律的に明確に分離するが、fear/surpriseはほぼ重なる（silhouette 0.026） | fear/surpriseの韻律制御精度は限定的 | スタイル選択（ささやき、ヒソヒソ等）でカバー |
| 制約03 | JVNVは演技音声であり感情の「ステレオタイプ」を反映する可能性 | 微妙な感情ニュアンスは捕捉しきれない | 94%認識率は日本語話者にとって自然なパターンであり、合目的的 |
| 制約04 | Phase 1グリッドサーチは約200テキストで実施 | 未知テキストへの汎化はPhase 0の精度がボトルネック | Phase 0の精度を優先的に改善。テキスト追加は将来課題 |
| 制約05 | JVNVは4話者・1,615件と限定的 | 教師データの多様性に制約 | Phase 4でE2Eモデル音声による補完を検討 |

---

## フェーズ間依存関係

```
Phase 0（テキスト感情分類）
  │  出力: 6D感情確率ベクトル
  │  Go/No-Go → Phase 1へ
  ▼
Phase 1（VOICEVOXグリッドサーチ）
  │  出力: 25,416件の音声 + メタデータ
  ▼
Phase 2（検証実験 V-01/V-02/V-03）
  │  V-01: JVNV感情分離性 → Conditional Go
  │  V-02: VOICEVOX韻律応答性 → Go
  │  V-03: ドメインギャップ・マッチング → Go
  ▼
Phase 3（韻律マッチング・パラメータ生成・統合）
  │  3a: 基盤構築（Phase 0再学習含む）
  │  3b: パラメータ生成器
  │  3c: スタイル統合
  │  3d: 主観評価・最終調整
  ▼
Phase 4（拡張: 他TTS, モーラレベル, 感情強度, E2E補完）
```

---

## 文書間の関係

| 文書 | 内容 | 関係 |
|------|------|------|
| **本文書（EB-USDM）** | EmotionBridge全体の要求仕様 | マスター文書 |
| **EB3-USDM** | Phase 3詳細要求仕様書 | 本文書のEB-P3-01を詳細化 |
| **EB-P0-BD-001** | Phase 0基本設計書（旧設計） | 旧設計の参考。Phase 0再設計は本文書のEB-P0-01に記載 |
| **Phase 3提案書（v1.0）** | 設計転換の経緯と検証結果 | 本文書の根拠となる技術文書 |

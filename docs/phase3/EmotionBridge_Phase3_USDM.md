# EmotionBridge Phase 3 要求仕様書（USDM形式）

> **プロジェクト**: EmotionBridge — テキスト感情→VOICEVOX韻律パラメータ自動変換  
> **対象フェーズ**: Phase 3（v1.0 新設計）  
> **作成日**: 2026-02-17  
> **ステータス**: 初版  
> **前提**: Phase 0–2 完了済み、V-01/V-02/V-03 検証完了済み、SERベース設計全面廃止済み  
> **ID体系**: `EB3-[カテゴリ番号]-[下位要求番号]-[仕様連番3桁]`

---

## カテゴリ: A. JVNV韻律プロファイル構築（オフライン教師データ）

### 要求ID: EB3-A01

| 項目 | 内容 |
|------|------|
| **要求** | JVNVコーパスの感情音声から非言語発話区間を除外し、eGeMAPS韻律特徴量を抽出し、話者内正規化を行い、感情別韻律プロファイル（重心＋分布）を構築する |
| **理由** | 旧設計のemotion2vec+（weak teacher、ドメインギャップ未検証）に代わる物理量ベースの正解信号が必要であり、JVNV（94%認識率、CC BY-SA 4.0）の韻律特徴量がその役割を果たすことをV-01/V-03で確認済みであるため |
| **説明** | JVNVは4話者・6感情（anger, disgust, fear, happy, sad, surprise）・1,615件・3.94時間の日本語感情音声コーパス。V-01でペアワイズsilhouetteによる感情分離性を確認済み（anger–sad: 0.284, happy–sad: 0.195）。全体silhouette 0.009は6感情離散クラスタとしては不成立だが、カテゴリ直接マッチング方式には十分 |

#### 下位要求: EB3-A01-01（NV区間除外）

| 項目 | 内容 |
|------|------|
| **要求** | JVNVの非言語発話（笑い声、泣き声等）の時間区間をNVラベルに基づき除外する |
| **理由** | 非言語発話は韻律特徴量の分布を歪め、感情プロファイルの精度を低下させるため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-A01-01-001 | \<除外方法\> | NVラベルの時間区間を無音化する（切り詰めではなく、時間構造を保持する） | 切り詰めると前後の韻律特徴量の時間的整合性が崩れる |
| EB3-A01-01-002 | \<除外対象\> | JVNVのアノテーションに含まれるNV（Non-Verbal）ラベルが付与されたすべての区間を対象とする | |

#### 下位要求: EB3-A01-02（韻律特徴量抽出）

| 項目 | 内容 |
|------|------|
| **要求** | NV除外済みのJVNV音声からopenSMILE eGeMAPSv02で韻律特徴量を抽出する |
| **理由** | eGeMAPSはAffective Computing分野の標準的特徴量セット（被引用2,346）であり、88Dの物理量として解釈可能な韻律記述を提供するため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-A01-02-001 | \<特徴量セット\> | openSMILE eGeMAPSv02の88パラメータをフルセットで使用する | V-01でTier1サブセット（11D）はペアワイズ分離度が向上したが全体silhouetteは改善しなかったため、フルセットを維持。将来的な特徴量選択の余地あり |
| EB3-A01-02-002 | \<F0スケール\> | F0関連特徴量はeGeMAPSの内蔵セミトーンスケール（27.5Hz基準）で出力する。追加変換は行わない | |
| EB3-A01-02-003 | \<ツール\> | 抽出にはopenSMILEを使用する。商用化時はlibrosa+pyworldによる代替実装、またはopenSMILE商用ライセンス取得を検討する | openSMILEは研究無償・商用要ライセンス |

#### 下位要求: EB3-A01-03（話者内正規化）

| 項目 | 内容 |
|------|------|
| **要求** | 抽出した韻律特徴量を話者ごとにz-score正規化する |
| **理由** | 話者間の声質差（基本周波数の絶対値等）を除去し、感情による韻律変動のみを比較可能にするため。V-03で正規化の有効性を確認済み（Wasserstein: 15.42→0.15） |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-A01-03-001 | \<正規化単位\> | JVNV話者4名それぞれについて、当該話者の全感情発話からμ, σを算出し、z-score正規化を適用する | |
| EB3-A01-03-002 | \<正規化対象\> | 88D特徴量の全次元に対してz-score正規化を適用する | |

#### 下位要求: EB3-A01-04（感情別韻律プロファイル構築）

| 項目 | 内容 |
|------|------|
| **要求** | 正規化済み韻律特徴量から、6感情それぞれの韻律プロファイル（重心＋分布）を構築する |
| **理由** | 各感情の韻律的「正解」を88D空間上の点（重心）として定義し、VOICEVOXとのマッチングの基準点とするため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-A01-04-001 | \<重心計算\> | 各感情 e ∈ {anger, disgust, fear, happy, sad, surprise} について、正規化済みeGeMAPS 88Dベクトルの算術平均を重心 centroid\_e とする | |
| EB3-A01-04-002 | \<分布情報\> | 重心に加え、各感情の特徴量分布（共分散行列または各次元の標準偏差）を保持する | 将来のマハラノビス距離等への拡張に備える |

---

## カテゴリ: B. VOICEVOX韻律応答空間構築（オフライン教師データ）

### 要求ID: EB3-B01

| 項目 | 内容 |
|------|------|
| **要求** | Phase 1で生成済みのVOICEVOXグリッドサーチ音声からeGeMAPS韻律特徴量を抽出し、キャラクタ/スタイル内正規化を行い、各サンプルにJVNV感情プロファイルとの韻律距離を付与する |
| **理由** | VOICEVOXの5D制御パラメータが韻律空間上でどの感情プロファイルに近い音声を生み出すかを定量化し、感情ごとの推奨パラメータを導出するため。V-02で5D全軸の韻律応答性をGo判定済み |
| **説明** | Phase 1グリッドサーチ音声は25,416件。5Dパラメータ（pitch\_shift, pitch\_range, speed, energy, pause\_weight）の組み合わせで生成済み |

#### 下位要求: EB3-B01-01（VOICEVOX韻律特徴量抽出・正規化）

| 項目 | 内容 |
|------|------|
| **要求** | グリッドサーチ音声からeGeMAPS特徴量を抽出し、style\_id内z-score正規化を適用する |
| **理由** | JVNV韻律プロファイルとの比較を可能にするため、同一の特徴量空間・正規化手法で統一する必要がある |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-B01-01-001 | \<特徴量\> | EB3-A01-02と同一のopenSMILE eGeMAPSv02（88D）で抽出する | |
| EB3-B01-01-002 | \<正規化単位\> | VOICEVOXのstyle\_idごとに全グリッドサーチ音声からμ, σを算出し、z-score正規化を適用する | V-03で正規化後overlap ratio 0.72を確認済み |
| EB3-B01-01-003 | \<対象キャラクタ\> | 主要ターゲット: ずんだもん（style\_id: 3, 1, 7, 5, 22, 38, 75, 76）。副ターゲット: 四国めたん（style\_id: 2, 0, 6, 4, 36, 37） | |

#### 下位要求: EB3-B01-02（韻律距離計算・推奨パラメータ導出）

| 項目 | 内容 |
|------|------|
| **要求** | 各VOICEVOXサンプルと各感情プロファイル重心との韻律距離を計算し、感情ごとに韻律距離上位k件の制御パラメータを推奨パラメータ候補として抽出する |
| **理由** | パラメータ生成器の教師データとなる「この感情にはこのパラメータ」の対応関係を、物理量ベースで構築するため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-B01-02-001 | \<距離関数\> | 正規化後88D空間でのユークリッド距離を使用する | V-03のマッチングで文献整合的な結果を得た実績あり |
| EB3-B01-02-002 | \<推奨パラメータ\> | 各感情eについて、韻律距離が最小のk件のVOICEVOXサンプルの5D制御パラメータを推奨パラメータ候補とする | kは暫定（T.B.D）。Phase 3bのハイパーパラメータ調整で決定。決定者: プロジェクト実装者 |
| EB3-B01-02-003 | \<教師値\> | 推奨パラメータ候補k件の中央値を教師値とする（外れ値に頑健にするため、平均ではなく中央値） | |

---

## カテゴリ: C. テキスト感情分類器（Phase 0 再設計）

### 要求ID: EB3-C01

| 項目 | 内容 |
|------|------|
| **要求** | 入力テキストを6感情カテゴリに分類し、各感情の確率分布（6Dベクトル）を出力する感情分類器を構築する |
| **理由** | 推論パイプラインの入口として、テキストから感情情報を抽出する必要がある。旧Phase 0（8D Plutchik、trust相関0.36でNo-Go）から6感情カテゴリに切り替えることで、構造的問題を解消し、JVNV感情ラベルと直接対応させるため |
| **説明** | 旧設計のNo-Go主因であったtrustとanticipationを除外。6感情はJVNVの感情ラベル（anger, disgust, fear, happy, sad, surprise）と1対1で対応する |

#### 下位要求: EB3-C01-01（WRIME感情マッピング）

| 項目 | 内容 |
|------|------|
| **要求** | WRIMEコーパスの8感情強度をJVNVの6感情カテゴリにマッピングし、学習データを構築する |
| **理由** | WRIMEはPlutchik 8感情で標注されており、JVNV 6感情との対応を定義しないと学習データとして使用できないため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-C01-01-001 | \<感情マッピング\> | joy→happy, sadness→sad, anger→anger, fear→fear, disgust→disgust, surprise→surprise の直接対応で変換する | |
| EB3-C01-01-002 | \<除外感情\> | anticipation, trust は除外する（JVNVに対応する感情カテゴリが存在しないため） | |
| EB3-C01-01-003 | \<ラベル変換\> | WRIMEの連続強度値から6クラス分類ラベルへの変換方式を定義する | 暫定（T.B.D）: argmax方式、閾値方式等を比較実験で決定。Phase 3a完了時までに決定 |

#### 下位要求: EB3-C01-02（分類モデル学習）

| 項目 | 内容 |
|------|------|
| **要求** | BERTベースの6クラス感情分類モデルを学習する |
| **理由** | 旧Phase 0の8D出力から6Dを抽出する後処理方式も検討したが、不要な感情軸（trust, anticipation）の干渉を排除するため、6クラス分類ヘッドでの再学習を採用する |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-C01-02-001 | \<ベースモデル\> | tohoku-nlp/bert-base-japanese-whole-word-masking を使用する | 旧Phase 0と同一のベースモデル |
| EB3-C01-02-002 | \<出力層\> | 6クラス分類ヘッド（Softmax）を追加し、各感情の確率分布を出力する | |
| EB3-C01-02-003 | \<学習データ\> | EB3-C01-01で構築したWRIME→6感情マッピング済みデータを使用する | WRIMEは研究用途ライセンス。商用利用時は要確認 |

---

## カテゴリ: D. パラメータ生成器

### 要求ID: EB3-D01

| 項目 | 内容 |
|------|------|
| **要求** | テキスト感情確率（6D）を入力として受け取り、VOICEVOXの5D制御パラメータを出力する軽量ニューラルネットワークを学習する |
| **理由** | 感情分類結果から韻律制御パラメータへの変換を自動化し、テキスト入力だけで感情表現付き音声を生成可能にするため。混合感情（「怒り0.7、驚き0.3」等）への対応も必要 |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-D01-001 | \<入力\> | Phase 0感情分類器の出力である6D確率ベクトル（各感情の確率値、合計1.0）を入力とする | |
| EB3-D01-002 | \<出力\> | 5D制御パラメータ（pitch\_shift, pitch\_range, speed, energy, pause\_weight）を出力する。各パラメータは[-1.0, +1.0]の範囲 | |
| EB3-D01-003 | \<アーキテクチャ\> | Linear(6, 64) → ReLU → Dropout(0.3) → Linear(64, 5) → tanh で構成する | 入力6Dに対して極めて軽量な構成 |
| EB3-D01-004 | \<損失関数\> | 重み付きMSEを使用する: loss = Σ\_e p(e\|text) × MSE(predicted\_params, recommended\_params\_e)。テキスト感情確率の各成分を重みとして、各感情の推奨パラメータとの加重平均二乗誤差を最小化する | 混合感情に対して推奨パラメータの中間的な値が学習される |
| EB3-D01-005 | \<教師データ\> | EB3-B01-02で導出した感情別推奨パラメータ（上位k件の中央値）を教師値とする | |
| EB3-D01-006 | \<出力制約\> | 出力層にtanhを適用し、パラメータ値を[-1.0, +1.0]に制約する | VOICEVOXの制御パラメータ範囲と一致 |

---

## カテゴリ: E. スタイル選択

### 要求ID: EB3-E01

| 項目 | 内容 |
|------|------|
| **要求** | テキスト感情カテゴリに基づき、VOICEVOXキャラクターの音声スタイルを自動選択する機構を構築する |
| **理由** | 5D韻律パラメータのみでは感情表現に限界がある（聴取確認: 「ニュートラルよりは確実にマシだが劇的ではない」）。VOICEVOXのスタイル（あまあま、ツンツン、ささやき等）を第6の制御軸として導入し、表現力を拡張するため。特にfear/surpriseは韻律分離が弱く（V-01: silhouette 0.026）、スタイル選択でカバーする戦略が現実的 |

#### 下位要求: EB3-E01-01（スタイル別韻律プロファイル構築）

| 項目 | 内容 |
|------|------|
| **要求** | 各キャラクターの各スタイルについて、eGeMAPS韻律プロファイルを構築する |
| **理由** | JVNV感情プロファイルとの韻律距離を算出し、感情→スタイルの最適マッピングをデータに基づいて決定するため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-E01-01-001 | \<構築方法\> | 各スタイルのグリッドサーチ音声（EB3-B01-01で抽出済み）のeGeMAPS特徴量を正規化し、スタイルごとの重心を算出する | |
| EB3-E01-01-002 | \<対象スタイル（ずんだもん）\> | ノーマル(3), あまあま(1), ツンツン(7), セクシー(5), ささやき(22), ヒソヒソ(38), ヘロヘロ(75), なみだめ(76) の8スタイル | |
| EB3-E01-01-003 | \<対象スタイル（四国めたん）\> | ノーマル(2), あまあま(0), ツンツン(6), セクシー(4), ささやき(36), ヒソヒソ(37) の6スタイル | |

#### 下位要求: EB3-E01-02（感情→スタイルマッピング）

| 項目 | 内容 |
|------|------|
| **要求** | 感情カテゴリごとに最適なスタイルをマッピングする |
| **理由** | 推論時に感情分類結果から自動的にスタイルを選択可能にするため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-E01-02-001 | \<Phase 3初期\> | ルールベースで定義する。各スタイルのeGeMAPSプロファイルとJVNV感情プロファイルの韻律距離が最小のスタイルを各感情のデフォルトとする | |
| EB3-E01-02-002 | \<Phase 3拡張\> | スタイル混合比率を含む学習ベースの選択に拡張する | 暫定（T.B.D）: Phase 3c実験結果に基づき実施判断。Phase 3c完了時までに決定 |

---

## カテゴリ: F. 推論パイプライン

### 要求ID: EB3-F01

| 項目 | 内容 |
|------|------|
| **要求** | テキストを入力として受け取り、感情分類、パラメータ生成、スタイル選択を経て、VOICEVOXで感情表現付き音声を生成する一貫したパイプラインを構築する |
| **理由** | EmotionBridgeのエンドツーエンド機能を実現し、ユーザーがテキスト入力のみで感情表現付き音声を得られるようにするため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-F01-001 | \<パイプライン構成\> | テキスト → Phase 0感情分類器（6D確率） → パラメータ生成器（5Dパラメータ） → スタイル選択 → VOICEVOX音声合成 → 音声出力 の順で処理する | |
| EB3-F01-002 | \<制御パラメータ\> | 5Dパラメータの定義: pitch\_shift（F0平均高低）、pitch\_range（F0変動幅）、speed（発話速度）、energy（音響エネルギー）、pause\_weight（休止長）。各パラメータは[-1.0, +1.0] | V-02で全軸の韻律応答性を確認済み |
| EB3-F01-003 | \<VOICEVOX連携\> | VOICEVOXエンジンのローカルAPIを呼び出し、style\_idと5D制御パラメータを渡して音声を生成する | VOICEVOXエンジンのローカル起動が前提 |
| EB3-F01-004 | \<デフォルト動作\> | 感情分類の確信度が低い場合（全クラスの確率が均等に近い場合）、ニュートラルスタイルかつ5Dパラメータをゼロとして出力する | 閾値は暫定（T.B.D）: Phase 3bの実験で決定 |

---

## カテゴリ: G. 評価

### 要求ID: EB3-G01

| 項目 | 内容 |
|------|------|
| **要求** | パイプライン全体の品質を定量評価と主観評価の両面で検証し、Phase 3の成果を判定する |
| **理由** | 韻律マッチングの物理的妥当性（定量）と人間が知覚する感情表現の自然さ（主観）は別の指標であり、両方を確認しないとシステムの有効性を判断できないため |

#### 下位要求: EB3-G01-01（定量評価）

| 項目 | 内容 |
|------|------|
| **要求** | 韻律距離、感情分類一致率、パラメータ予測精度の3指標で定量評価を実施する |
| **理由** | 各段階の品質をV-03のベースラインと比較し、パイプライン統合による劣化がないことを確認するため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-G01-01-001 | \<ラウンドトリップ韻律距離\> | 予測パラメータで生成した音声のeGeMAPSとJVNV感情プロファイルとの距離を計算する。目標: V-03のマッチング距離（mean 3.84）を下回ること | |
| EB3-G01-01-002 | \<感情分類一致率\> | 生成音声を感情分類器に通し、元のテキスト感情と一致するかを測定する。目標: anger/happy/sadで60%以上 | fear/surprise/disgustは韻律分離が弱いため目標値を設けない |
| EB3-G01-01-003 | \<パラメータ予測MAE\> | 推奨パラメータとの平均絶対誤差を計算する。目標: 各軸0.2以内 | |

#### 下位要求: EB3-G01-02（主観評価）

| 項目 | 内容 |
|------|------|
| **要求** | A/Bテスト、MOS評価、感情識別テストの3手法で主観評価を実施する |
| **理由** | 定量指標だけでは人間が知覚する感情表現の自然さを判断できないため |

##### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-G01-02-001 | \<A/Bテスト\> | デフォルト韻律（ニュートラル）vs EmotionBridge韻律の対で提示し、どちらが感情表現として適切かを回答させる | |
| EB3-G01-02-002 | \<5段階MOS\> | 感情表現の自然さを5段階（1: 全く不自然 〜 5: 完全に自然）で評価させる | |
| EB3-G01-02-003 | \<感情識別テスト\> | 音声を聞いて感情を回答させ、正解率を測定する | JVNVの94%認識率がベンチマーク |
| EB3-G01-02-004 | \<評価規模\> | まず少人数（5–10名）のパイロット評価を実施し、結果に基づき大規模評価の実施判断を行う | Phase 3dで実施 |

---

## カテゴリ: H. 配布・セキュリティ

### 要求ID: EB3-H01

| 項目 | 内容 |
|------|------|
| **要求** | コードと設計文書を公開し、データ・モデル重み・中間成果物は公開せず、利用者が自らデータを準備して初めてパイプラインを動かせる構造にする |
| **理由** | 音声合成の自動化を安易に悪用する用途（無断での大量コンテンツ生成等）への技術的フィルターとして機能させるため。手順を理解し実行できる開発者のみが利用可能となる |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-H01-001 | \<公開物\> | 実験コード（韻律抽出、正規化、マッチング、学習、推論の全スクリプト）、設計文書・調査報告書、手順書（環境構築、データ準備、実行手順）を公開する | |
| EB3-H01-002 | \<非公開物\> | JVNVから抽出した韻律特徴量データ、Phase 1グリッドサーチ音声および抽出済み特徴量、学習済みモデルの重み、正規化パラメータ・スコアテーブル等の中間成果物は公開しない | |
| EB3-H01-003 | \<利用者の準備事項\> | 利用者は以下を自ら準備する: (1) JVNVコーパスのダウンロード、(2) VOICEVOXエンジンのローカル起動、(3) グリッドサーチ音声の自己生成、(4) 韻律特徴量の自己抽出 | |

---

## カテゴリ: N. 非機能要求

### 要求ID: EB3-N01（ライセンス適合性）

| 項目 | 内容 |
|------|------|
| **要求** | 使用するすべての外部リソースのライセンス条件を遵守し、ライセンス上のリスクを明示的に管理する |
| **理由** | ライセンス違反はプロジェクトの配布・商用化を阻害し、法的リスクを生じるため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-N01-001 | \<JVNV\> | CC BY-SA 4.0に準拠する。派生物もCC BY-SAとなる。韻律特徴量データ自体は再配布しない | |
| EB3-N01-002 | \<WRIME\> | 研究用途のみのライセンスに準拠する。商用利用時は権利者に確認する。学習済み重みの配布可否も確認する | 暫定（T.B.D）: 商用化検討時に確認。商用化判断時までに決定 |
| EB3-N01-003 | \<openSMILE\> | 研究フェーズでは無償利用。商用化時はlibrosa+pyworldによる代替実装、またはopenSMILE商用ライセンス取得のいずれかを選択する | |
| EB3-N01-004 | \<VOICEVOX\> | キャラクターごとの利用規約に準拠する。商用利用条件はキャラクターごとに異なるため、個別に確認する | |

### 要求ID: EB3-N02（再現性）

| 項目 | 内容 |
|------|------|
| **要求** | 第三者が手順書に従ってパイプラインを再現可能であること |
| **理由** | 研究としての信頼性と、コミュニティへの貢献（配布方針に基づく「コードは動作するが、データは自分で作る」の設計原理）を実現するため |

#### 仕様一覧

| 仕様ID | 仕様グループ | 仕様 | 備考 |
|--------|-------------|------|------|
| EB3-N02-001 | \<環境構築手順\> | 必要なライブラリ・ツールのバージョンを固定し、環境構築手順を文書化する | |
| EB3-N02-002 | \<データ準備手順\> | JVNVダウンロード、VOICEVOXセットアップ、グリッドサーチ実行、特徴量抽出の各ステップを手順書に記載する | |
| EB3-N02-003 | \<実行手順\> | 学習と推論の実行手順、期待される出力例を手順書に記載する | |

---

## 開発ロードマップとの対応

| ロードマップ | 対応する要求ID |
|-------------|---------------|
| Phase 3a: 基盤構築 | EB3-A01, EB3-B01, EB3-C01, EB3-E01-01 |
| Phase 3b: パラメータ生成器 | EB3-D01, EB3-B01-02, EB3-G01-01 |
| Phase 3c: スタイル統合 | EB3-E01-02, EB3-F01 |
| Phase 3d: 主観評価・最終調整 | EB3-G01-02, EB3-H01, EB3-N02 |

---

## 暫定事項（T.B.D）一覧

| 仕様ID | 内容 | 決定期限 | 決定者 |
|--------|------|----------|--------|
| EB3-B01-02-002 | 推奨パラメータ候補のk値 | Phase 3b完了時 | プロジェクト実装者 |
| EB3-C01-01-003 | WRIME連続強度→6クラスラベルの変換方式 | Phase 3a完了時 | プロジェクト実装者 |
| EB3-E01-02-002 | スタイル混合比率の学習ベース選択の実施判断 | Phase 3c完了時 | プロジェクト実装者 |
| EB3-F01-004 | 低確信度時のニュートラルフォールバック閾値 | Phase 3b完了時 | プロジェクト実装者 |
| EB3-N01-002 | WRIME商用利用可否の確認 | 商用化判断時 | プロジェクト実装者 |

---

## 既知の制約（設計上の前提）

以下はシステムの制約として受容する事項であり、要求・仕様としては管理しない。

1. **韻律パラメータ制御の限界**: VOICEVOXの5D制御パラメータの範囲・粒度に依存する。劇的な感情表現ではなく「ニュートラルより確実にマシ」が現実的な目標水準
2. **感情分離の非均一性**: anger/happy/sadは韻律的に明確に分離するが、fear/surpriseはほぼ重なる。後者の韻律制御精度は限定的
3. **演技音声の正解性**: JVNVは演技音声であり感情のステレオタイプを反映する可能性があるが、94%認識率は日本語話者にとって自然で認識可能なパターンであることを示しており、合目的的
4. **テキスト多様性**: Phase 1グリッドサーチは約200テキストで実施。未知テキストへの汎化はPhase 0の精度がボトルネックとなる可能性がある

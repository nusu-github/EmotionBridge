data:
  dataset_name: shunk031/wrime
  dataset_config_name: ver1
  text_field: sentence
  label_source: avg_readers
  max_length: 128
  use_official_split: false
  filter_max_intensity_lte: 1
  stratify_after_filter: true
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  random_seed: 42

model:
  pretrained_model_name: tohoku-nlp/bert-base-japanese-whole-word-masking
  bottleneck_dim: 256
  dropout: 0.1

train:
  output_dir: artifacts/phase0
  batch_size: 16
  num_epochs: 10
  bert_lr: 0.00002
  head_lr: 0.001
  weight_decay: 0.01
  warmup_ratio: 0.1
  early_stopping_patience: 3
  device: cuda
  num_workers: 2
  pin_memory: true
  log_every_steps: 50
  gradient_accumulation_steps: 2
  mixed_precision: "fp16"
  emotion_weight_mode: inverse_mean
  emotion_weight_epsilon: 0.0001
  emotion_weight_normalize: true
  emotion_weights: null

eval:
  go_macro_mse_max: 0.05
  go_top6_min_pearson: 0.5
  go_anger_trust_min_pearson: 0.3
  go_top1_acc_min: 0.6
